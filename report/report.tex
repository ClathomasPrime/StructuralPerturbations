% This is based on the LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
% See http://www.springer.com/computer/lncs/lncs+authors?SGWID=0-40209-0-0-0
% for the full guidelines.
%

\documentclass{llncs}

\usepackage[noend]{algpseudocode}
\usepackage{algorithm}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{tkz-graph}
\usepackage{tikz-cd}
\usepackage{varwidth}
\usepackage{qtree}
\usepackage{mathtools}
\usepackage{tabularx}

\newlength\Colsep
\setlength\Colsep{10pt}
\usepackage{lipsum}

\usetikzlibrary{decorations.markings}

\newcommand{\zero}{\mathrm{zero}}
\newcommand{\const}{\mathrm{const}}
\newcommand{\afin}{\mathrm{affine\ in\ }}
\newcommand{\linin}{\mathrm{linear\ in\ }}

\DeclareMathOperator{\Perm}{Perm}
\DeclareMathOperator{\Conj}{Conj}
\DeclareMathOperator{\SimultConj}{SimultConj}
\DeclareMathOperator{\len}{length}
\DeclareMathOperator{\ret}{ret}

\newlength\myindent
\setlength\myindent{2em}
\newcommand\bindent{%
  \begingroup
  \setlength{\itemindent}{\myindent}
  \addtolength{\algorithmicindent}{\myindent}
}
\newcommand\eindent{\endgroup}

\title{Verifying Robustness of Programs Under Structural Perturbations}
\author{Jacob Bond and Clay Thomas}
\institute{Purdue University}

\begin{document}

\maketitle

% \begin{abstract}
% \end{abstract}

\section{Introduction}

The question of robustness is fundamental to the subject of programming by example (PBE).  Robustness of a program is the property that the program behaves predictably on uncertain inputs \cite{chaudhuri12}.  In the PBE paradigm, there is, by definition, an uncertainty about the intent of the user, and therefore, it is desirable that a program synthesizer behave predictably with regards to this uncertainty.

Consider an attempt to specify the \(\max\) function by providing to a program synthesizer the examples \((13, 15) \mapsto 15\), \((-23, 19) \mapsto 19\), and \((-75, -13) \mapsto -13\).  In order to synthesize a simpler program, the result will likely be the program \verb!P(a,b):=return b;!.  Two issues are at play here: the program syntehsizer is not robust and the synthesized program is also not robust.

First, the program synthesizer is not robust as transposing the inputs of all of the examples would result in the program \verb!P(a,b):=return a;!, while transposing just a single input would result in the correct program

\hspace{2\parindent}\verb!P(a,b):=return a>b?a:b;!.

Second, the program which is synthesized is not robust as \verb!P(a,b)!\(\not=\)\verb!P(b,a)!.  That is, the program does not behave predictably under uncertainty of the order of the arguments.  If the program which is synthesized is required to be robust with respect to uncertainty in the order of the input, neither \verb!P(a,b):=return a;! nor \verb!P(a,b):=return b! would be viable candidates, and the synthesizer would be forced to return

\hspace{2\parindent}\verb!P(a,b):=return a>b?a:b;!.

Moreover, a synthesizer which returns robust programs will itself be more robust.  Let \(\mathcal{I}_{1} = (I_{1}, O_{1})\) and \(\mathcal{I}_{2} = (I_{2}, O_{2})\) be two input-output pairs for a program synthesizer which differ by a small perturbation.  If the program \(\mathcal{P}_{1}\) returned by the synthesizer on input \(\mathcal{I}_{1}\) is robust, then \(\mathcal{P}_{1}(I_{2})\) will approximate \(O_{2}\) because \(I_{2}\) approximates \(I_{1}\).  For this reason, \(\mathcal{P}_{2}\), the program returned on input \(\mathcal{I}_{2}\), should only differ from \(\mathcal{P}_{1}\) by a small amount.

Thus, the issue of robustness in PBE can be addressed by verifying robustness, either of the synthesized programs or even of the synthesizer as a whole.  However, verification of robustness requires the ability to reason about robustness.

\section{Related Work}

\paragraph{Relational Logics} Benton \cite{benton} established a Relational Hoare Logic in order to reason about relational properties, properties which consider two, usually distinct, programs.  Barthe et al. \cite{barthecrypto,bartheprivacy} extended Benton's Relational Hoare Logic to probabalistic programs in order to reason about cryptographic protocols and differential privacy.

\paragraph{Self-Composition} Barthe et al. \cite{barthecomposition} applied self-composition, sequential running of renamed copies of the original program, to study secure information flow.  Terauchi \& Aiken \cite{terauchi05} built on this work by applying a type-based approach to complement self-composition.

\paragraph{\(2\)-Safety Properties} In \cite{terauchi05}, Terauchi \& Aiken introduce the term \(2\)-safety property to describe a property which requires two execution traces in order to reason about it.  A general approach to the verification of \(2\)-safety properties is the creation of a product program \cite{bartheproduct}, a program which interleaves two copies of a given program to create a new program.  It \cite{bartheanalysis}, Barthe et al. analyzes various relational program logics, as well as different notions of product programs.

\paragraph{Continuity} Hamlet \cite{hamlet02} considered the concept of program continuity, but declared that automating verification of continuity for programs with loops was infeasible.  Chaudhuri et al. \cite{chaudhuri10,chaudhuri11} consider the continuity and Lipschitz continuity of programs over the real numbers. Samanta et al. \cite{samanta13} and Henzinger et al. \cite{samanta14} investigate the use of Lipschitz continuity for proving robustness in the context of transducers.

\paragraph{Robustness} Robustness for control systems was investigated by Majumdar and Saha \cite{majumdar09} and for general programs by \cite{chaudhuri11}.  Additionally, the robustness of networked systems was explored by Samanta et al. \cite{samanta13a}.

\paragraph{\(k\)-Safety Properties} Clarkson and Schneider \cite{clarkson08} introduced \(k\)-safety properties as a generalization of this idea.  Sousa and Dillig \cite{sousa16} formulated a verification algorithm in order to automate checking of \(k\)-safety properties.

\section{Preliminaries}

\subsection{Continuity and Lipschitz Continuity}

%Given \(\varepsilon \in \mathbb{R}^{+}\) and a set of input variables \(In\), a state \(\sigma'\) is an \(\varepsilon\) perturbation of a state \(\sigma\), denoted \(Pert_{\varepsilon,In}(\sigma, \sigma')\),  if
%\begin{enumerate}
%    \item for all \(x \in In\), \(d\big(\sigma(x), \sigma'(x)\big) < \varepsilon\), and
%    \item for all \(y \notin In\), \(\sigma(y) = \sigma'(y)\) \cite{chaudhuri10}.
%\end{enumerate}
%
%Given \(\varepsilon \in \mathbb{R}^{+}\) and a set of variables \(V\), a state \(\sigma'\) is \(\varepsilon\)-close to a state \(\sigma\), denoted \(\sigma \approx_{\varepsilon,V} \sigma'\), if for all \(x \in V\), \(d\big(\sigma(x), \sigma'(x)\big) < \varepsilon\) \cite{chaudhuri10}.
%
A program \(\mathcal{P}\) is continuous at a state \(\sigma\) with respect to input variables \(In\) and observable variables \(Obs\) if for all \(\varepsilon \in \mathbb{R}^{+}\), there is a \(\delta \in \mathbb{R}^{+}\) so that if \(\sigma'\) satisfies
%\(Pert_{\delta,In}(\sigma,\sigma')\) implies \(P(\sigma)\approx_{\varepsilon,Obs}\mathcal{P}(\sigma')\) \cite{chaudhuri10}.
\begin{enumerate}
    \item for all \(x \in In\), \(d\big(\sigma(x), \sigma'(x)\big) < \varepsilon\) and
    \item for all \(y \notin In\), \(\sigma(y) = \sigma'(y)\),
\end{enumerate}
then for all \(x \in Obs\), \(d\big(\mathcal{P}(\sigma)(x), \mathcal{P}(\sigma')(x)\big)\) \cite{chaudhuri10}.

Lipschitz continuity of a mathematical function \(f\) is the property that there exists a real number \(K \in \mathbb{R}^{+}\) so that for all \(x_{1}, x_{2}\), \(d\big(f(x_{1}), f(x_{2})\big) \leq K\,d(x_{1}, x_{2})\).  Similarly, a program \(\mathcal{P}\) is robust at a state \(\sigma\)  with respect to the input variable \(x_{in}\) and output variable \(x_{out}\) if for all \(\varepsilon \in \mathbb{R}^{+}\),
\begin{enumerate}
    \item \(d\big(\sigma(x_{in}), \sigma'(x_{in})\big) < \varepsilon\) and
    \item for all \(y \not= x\), \(\sigma(y) = \sigma'(y)\)
\end{enumerate}
implies that \(d\big(\mathcal{P}(\sigma)(x_{out}), \mathcal{P}(\sigma')(x_{out})\big) < K\varepsilon\), where \(K\) is a real-valued function of the size of \(x_{in}\) \cite{chaudhuri11}.

\subsection{Permutations}
\label{perms}

A permutation is a bijection from a set \(\Omega\) to itself \cite{dummitfoote}.  When \(\Omega\) is a finite set, a permutation can be specified using two-line notation by placing the elements of \(\Omega\) on one line, and their images under \(\sigma\) beneath them:

% increase the intercolumn spacing
\begin{center}
\begin{tabular*}{0.5\textwidth}{c@{\extracolsep{\fill}}c}
\(\sigma\):
\begin{tabular}{cccccc}
0 & 1 & 2 & 3 & 4 & 5\\
5 & 2 & 3 & 1 & 4 & 0
\end{tabular}
&
\(\sigma\):
\begin{tabular}{ccc}
a & b & c\\
a & c & b
\end{tabular}
\end{tabular*}
\end{center}

Similar to two-line notation, a permutation on \(\{0, \dotsc, N-1\}\) can be encoded in an array \(a\) of length \(N\) by placing the image of \(i\) in \(a[i]\).  The example \(\sigma\) above is encoded in an array as \(\sigma = [5, 2, 3, 1, 4, 0]\), so that \(\sigma(i) = \sigma[i]\).

The inverse \(\sigma^{-1}\) of a permutation \(\sigma\) is the permutation defined by
\[\sigma(i) = j \Longleftrightarrow \sigma^{-1}(j) = i.\]
For the permutation \(\sigma\) above,
\[\sigma^{-1}:\begin{tabular}{cccccc}
0 & 1 & 2 & 3 & 4 & 5\\
5 & 3 & 1 & 2 & 4 & 0
\end{tabular}.\]

% give first-order formula for being a permutation
\paragraph{First-Order Formula for a Permutation}
The property of being a permutation on \(\{0, \dotsc, N-1\}\) is encoded in the theory of arrays as
\begin{multline*}\Perm(a, N): N = \len(a) \wedge (\forall i. 0 \leq i < N \rightarrow 0 \leq a[i] < N) \wedge\\(\forall i,j. 0 \leq i < j < N \rightarrow a[i] \not= a[j]).\end{multline*}

\paragraph{Action on an Array}

Given a permutation \(\sigma\), \(\sigma\) can {\it act} on an array \(a\) as follows.  Let \(a = [37, 25, 19, 49, 81, 21]\) and \(\sigma\) be as above.  Then \(\sigma(3) = \sigma[3] = 1\) and applying \(\sigma\) to \(a\) results in the element of \(a\) at index \(3\), \(49\), being moved to index \(1\) in \(\sigma a\).  That is, \(\sigma a[1] = 49\) and \(a[3] = \sigma a[1] = \sigma a[\sigma[3]]\).  More generally,
\begin{equation}
\sigma a[\sigma[i]] = a[i] \Longleftrightarrow \sigma a[i] = a[\sigma^{-1}[i]].
\label{action}
\end{equation}

\paragraph{Generating Permutations}
For information on permutation groups, see \S1.3 in \cite{dummitfoote}.

\makeatletter
\renewcommand{\@cite}[1]{#1}
\makeatother
The permutations on \(N\) elements, \(S_{N}\), can all be expressed as compositions of the permutations [Exercises 3-4, \S3.5, \cite{dummitfoote}]
% increase the intercolumn spacing
\[\begin{tabular}{ccccc}
0 & 1 & 2 & \(\dotsm\) & \(N-1\)\\
1 & 0 & 2 & \(\dotsm\) & \(N-1\)
\end{tabular}
\qquad\textrm{and}\qquad
\begin{tabular}{ccccc}
0 & 1 & 2 & \(\dotsm\) & \(N-1\)\\
1 & 2 & 3 & \(\dotsm\) & 0
\end{tabular},\]
\makeatletter
\renewcommand{\@cite}[1]{[#1]}
\makeatother
where the first permutation is a transposition of \(0\) and \(1\) and the second permutation is a rotation of all of the elements by one position.

\subsection{Automata}
We consider two classes of automata: finite state machines (FSM) and finite state transducers (FST). All automata we consider are deterministic. Given an automata $A$, we denote by $A(s)$ the output of $A$ on input $s$. If $A$ is an FSM, we represent "accept" by $1$ and "reject" by $0$. Otherwise, $A$ is a finite state transducer (FST), and $A(s)$ is a string. For a FSM $A$, let $L(A)$ denote the set of strings accepted by $A$. (We do not define the language of an FST).

Recall that for any FSMs $A$ and $B$, the problem of determining whether $L(A) = L(B)$ is decidable. We can compose an FST $T$ and a FSM $A$, denoted $A \circ T$, to get another FSM.

We will assume that all input strings are terminated by a special end-of-input character \$.

\section{Robustness Properties}

The uncertainty with respect to which a program is robust can take many different forms.  Some common perturbations include
\begin{itemize}
\item numerical perturbations \cite{samanta14,chaudhuri10,chaudhuri11},
\item permutations of arrays and matrices,
\item simultaneous permutations of arrays.
\end{itemize}

\subsection{Continuity}

Robustness in the setting of numerical perturbations is realized by the property of continuity.  In many situations, the result of a program should be relatively stable with respect to any uncertainty in the input.  That is, if the input is perturbed, the output should vary only slightly, relative to the input perturbation.  This is exactly the concept of Lipschitz continuity.  if it is possible that the input has been slightly perturbed, the result of the program should not be drastically different.  As an example, sorting algorithms are \(1\)-Lipschitz.  If each element of the input array is perturbed by an amount no more than \(1\), then each element of the output array will be changed by no more than \(1\).

\subsection{Permutations}

%\begin{multline*}N = \len(a_{1}) \wedge \exists s. \Perm(s, N) \wedge \forall i. 0

Let \(F\) and \(G\) be the formulas
\begin{gather*}
    F:  \forall i. 0 \leq i < \len(a_{1}) \rightarrow a_{1}[i] = a_{2}[(i+1)\%\len(a_{1})],\\
        G: a_{1}[0] = a_{2}[1] \wedge a_{1}[1] = a_{2}[0] \wedge \forall i.\big( 2 \leq i < \len(a_{1}) \rightarrow a_{1}[i] = a_{2}[i] \big).
\end{gather*}
Then invariace of a program which takes an array as input can be specified by
\[\|\len(a_{1}) = \len(a_{2}) \wedge (F \vee G)\| \mathcal{P}(a) \|\ret_{1} = \ret_{2}\|.\]

\subsubsection{Sorting}

Sorting is one example of a procedure which is robust with respect to permuting the input.  Even in the face of uncertainty regarding the order of the input array, the result of procedure will not be altered.  The \verb!max! function is a special case of this invariance of sorting algorithms under permutation, which is the root of the incorrectness of the attempts to synthesize the \verb!max! function in Section 1.

\subsubsection{Searching}

Consider the function \verb!Find(a, x)! which returns the index of the element \verb!x! in the array \verb!a! or \(-1\) if \verb!x! is not an element of \verb!a!.  Let \(\sigma\) be a permutation and suppose that \verb!a[i]=x!.  Then from \eqref{action}
\[\sigma\verb!a[!\sigma(\verb!i!)\verb!]! = \verb!a[i]! = \verb!x!,\]
so that \verb!Find(!\(\sigma\)\verb!a, x)=!\(\sigma(\)\verb!i!\()\).  Considering \(\sigma\) as a permutation on nonnegative integers, \(\sigma(-1) = -1\) and \verb!Find(!\(\sigma\)\verb!a, x)=!\(\sigma(\)\verb!i!\()\) holds even in the case that \verb!x! is not an element of \verb!a!.  Thus, \verb!Find! is robust in that perturbing the input array by a permutation \(\sigma\) perturbs the output of \verb!Find! by the same permutation \(\sigma\).

\subsubsection{Adjacency Matrices}

% programs operating on adjacency matrices should either be invariant under permutations or behave similarly to searching

\subsection{Simultaneous Permutation}

Consider an algorithm for grading a multipart homework problem, which takes as input three arrays:  the student's responses, the correct answers, and the credit to be awarded for each part.  A reordering of the parts of the problem should not affect the credit which a student is awarded.  As reordering the parts of the problem corresponds to simultaneously permuting the three input arrays, the grading algorithm should be invariant under simultaneous permutations of the input arrays.  This property can be expressed using ideas from Section \ref{perms} by applying a transposition and a rotation simultaneously to each array.%  Using ideas from Section \ref{perms}, this property can be expressed as the conjunction of the following two formulas:
%
%\begin{multline*}x_{2}[1] = x_{1}[0] \wedge y_{2}[1] = y_{1}[0] \wedge z_{2}[1] = z_{1}[0] \wedge\\
%x_{2}[0] = x_{1}[1] \wedge y_{2}[0] = y_{1}[1] \wedge z_{2}[0] = z_{1}[1] \wedge\\
%\forall i.\, 2 \leq i < \len(y_{1}) \rightarrow (x_{2}[i] = x_{1}[i] \wedge y_{2}[i] = y_{1}[i] \wedge z_{2}[i] = z_{1}[i])
%\end{multline*}
%\begin{multline*}\len(y_{1}) = N \wedge (x_{2}[0] = x_{1}[N-1] \wedge y_{2}[0] = y_{1}[N-1] \wedge z_{2}[0] = z_{1}[N-1]) \wedge\\ \forall i.\, 1 \leq i < N \rightarrow (x_{2}[i] = x_{1}[i-1] \wedge y_{2}[i] = y_{1}[i-1] \wedge z_{2}[i] = z_{1}[i-1])
%\end{multline*}

%The first formula specifies that the first two parts of the problem are transposed, while the rest of the parts remain unchanged.  The second specifies a rotation by one of the parts of the problem.

\begin{algorithm}
\begin{algorithmic}
\Function{Grade}{responses, answers, credits}
\State points \(\gets\) 0
\For{0 \(\leq\) i \(\leq\) length(answers)}
\If{responses[i] \(-\) answers[i] \(=\) 0}
\State points \(\gets\) points \(+\) credits[i]
\EndIf
\EndFor
\Return{points}
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Verifying Robustness}

% double check this citation:
A 2-safety property is one which requires reasoning about two execution traces simultaneously \cite{terauchi05}.  Robustness is the property that given two inputs which are related by some form of uncertainty, the outputs should be related in a predictable way.  Thus, robustness is a 2-safety property.

% discuss using Descartes' algorithm to verify robustness

\subsection{Shortcomings Regarding Lipschitz-Continuity}

% discuss how the If rule of CHL can be improved for verifying continuity

\section{Invariance under permuting lists}
\label{permlists}

A different problem we have been thinking about is more discrete
and algebraic in nature.
We want to verify that programs are invariant under
permutations of their input arrays.

\subsection{Automata}
Given a program $P$ which takes a linear data type
as input. We may wish to verify that this program
is invariant under reordering of the array,
in other words, it is invariant under the action of $S_n$.
Denote the output of $P$ on input $s$ by $P(s)$.
Then we want to test whether $P(\sigma s) = P$
for all $\sigma \in S_n$.

As a first simplification, observe that is
suffices to check our condition on a set
of generators of $S_n$.
Concretely, let $\alpha = (1\ 2\ 3\ ...\ n)$
and let $\beta = (1\ 2)$.
Then any $\sigma \in S_n$ can be written as
a product of elements of $\{\alpha,\beta\}$,
say $\sigma = u_1 u_2\ldots u_m$ with
$u_i \in \{\alpha,\beta\}$.
So if we know that $P(\alpha s) = P(s)$
and $P(\beta s) = P(s)$, then
$P((u_1 u_2 \ldots u_m)s)
= P((u_2 \ldots u_m)s)
= \ldots = P(u_ms) = P(s) $.

For a fixed $n$ and $\sigma \in S_n$,
we can construct a finite state transducer
$T$ such that $T(s) = \sigma s$ for $|s|=n$.
However, this does not give us any
reasonable way of checking that a given
finite state machine is invariant under permutation
of the input string.
Instead, we will construct finite state
transducers $T_{\alpha}$ and $T_{\beta}$
such that for any $n$ and any string $s$
with $|s|=n$, we have
$T_{\alpha}(s)=(1\ 2\ \ldots\ n) s$ and
$T_{\beta}(s) = (1\ 2) s$.
Then, determining whether an FSM $M$ is
invariant under permutation of its inputs
is equivalent to determining whether
\[
  L(M \circ T_\alpha) = L(M) = L(M \circ T_\beta)
\]

We now construct $T_\alpha$.
For each symbol $a \in \Sigma$,
$T_\alpha$ has a transition from its start
state $s_0$ to $s_a$, while reading in put $a$ and
writing $\epsilon$ output.
For each $a$ and each $b\ne \$$, there is a
transition from $s_a$ to $s_a$, reading $b$
and writing $b$.
Then for each $a$, there is a transition from
$s_a$ to $s_1$, reading $\$$ and writing $a\$$.

We now construct $T_\beta$.
For each symbol $a \in \Sigma$,
$T_\alpha$ has a transition from its start
state $s_0$ to $s_a$, while reading in put $a$ and
writing $\epsilon$ output.
Each $s_a$ has a transition to $s_1$ while
reading input $b$ (for any $b\in \Sigma$)
and writing output $ba$.
Then $s_1$ simply has transitions to $s_1$,
reading any $a\in \Sigma$ and writing
back $a$.

\iffalse % maybe put this back in later
\subsection{Programs}
The previous section indicates a method for verifying
robustness of more general programs under permutation of inputs.
% The framework of \cite{sousa16} is constructed in order to verify properties of related runs of the same program. However, their proof rules also give
Given a procedure $F$ taking an array as argument, consider the functions $F_\alpha$, which first swaps the first two elements of the array, then computes $F$, and $F_\beta$, which moves the first element of the array to the back, then computes $F$. Then $F$ is invariant under permutation of its input if and only if $F$ is functionally equivalent to $F_\alpha$ and $F_\beta$.

Certainly this method is more efficient than checking invariance under a larger class of permutations. For DFAs, this simplification made the problem of permutation invariance solvable. This indicates that this simplification may aid in our analysis in a profound way. For example, this may be a much easier way of verifying this invariance compared to expressing permutations as a general $2$-safety property.
\fi

\section{Invariance under permuting binary search trees}

In the previous section~\ref{permlists}, we found a reduction
from checking \emph{all} permutations of a list to checking a small set of
permutations. It is natural to ask if there are other data types for which we
can do this. Binary search trees are one such case, where just like lists,
two permutations suffice to generate all equivalent binary search trees
(i.e. tree representing equivalent ordered lists).

Represent binary search trees by the algebraic data type
Then define two (partial) operations $\rho$ and $\theta$ on binary search trees
as follows:

\begin{algorithm}
  data Tree = Nil $|$ Branch Tree Int Tree
  \\ \\
  list Nil = [\ ] \\
  list (Branch left a right) = list(left) ++ [a] ++ list(right)
  \\ \\
  $\rho$(Branch (Branch LL a LR) b R)
  \\ \hphantom{df} = Branch LL a (Branch LR b R)
  \\ \\
  $\theta$(Branch (Branch LL a (Branch LRL b LRR)) c R)
  \\ \hphantom{df} = Branch LL a (Branch LR b R)
\end{algorithm}

\qroofx=2
\qroofy=1
\begin{tabular}{ccc}
 \Tree [.b [.a \qroof{LL}. \qroof{LR}. ] \qroof{R}. ]
    & $\xmapsto{\ \ \rho\ \ }$
    & \Tree [.a \qroof{LL}. [.b \qroof{LR}. \qroof{R}. ]  ]
  \\
  \Tree [.c [.a \qroof{LL}. [.b \qroof{LRL}. \qroof{LRR}. ]] \qroof{R}. ]
  & $\xmapsto{\ \ \theta\ \ }$
  & \Tree [.c [.b [.a \qroof{LL}. \qroof{LRL}. ] \qroof{LRR}. ] \qroof{R}. ]
\end{tabular}

\begin{theorem}
  If a program $P$ on binary search trees is invariant under $\rho$
  and $\theta$, then whenever $\mathrm{list}(t_1) = \mathrm{list}(t_2)$,
  we have $P(t_1) = P(t_2)$.
\end{theorem}
\begin{proof}
  Observe that if $P$ is invariant under $\rho$ and $\theta$,
  then $P$ is also invariant under $\rho^{-1}$ and $\theta^{-1}$.
  Thus, we need to show that any two binary search trees representing the same
  ordered list can be transformed into one another using only $\rho$,
  $\rho^{-1}$, $\theta$, and $\theta^{-1}$.
  Because these operations are invertible, it suffices to demonstrate that you
  can use them to transform any binary search tree into a ``degenerate list
  structure'', in which no subtree has a nonnull left child.

  Consider the following algorithm for adjusting a tree via $\rho$ and $\theta$:
  \begin{algorithm}[H]
    \begin{algorithmic}[1]
      \Function{Listify}{$t$}
      \While{$t$ has a right child}
        \State apply $\rho^{-1}$ to $t$
      \EndWhile
      \While{$t$ has a left child}
        \While{$t$'s left child has a right child}
          \State apply $\theta$ to $t$
        \EndWhile
        \State apply $\rho$ to $t$
      \EndWhile
      \EndFunction
    \end{algorithmic}
  \end{algorithm}

  I claim that this algorithm terminates with $t$ in degenerate list form.
  Proof: the first loop clearly terminates, and leave $t$ with a null right
  child. Thus, after the first loop, $t$'s right child is in degenerate list
  form.

  Consider the inner loop on line 5. This loop clearly always terminates,
  and leave the right subtree of $t$ unchanged.
  When this loop finishes, $t$'s left child has a null right child.
  Observe that if $\rho$ is applied to $t$ when $t$'s left child
  has a null right child AND $t$'s right child is in degenerate list form,
  then the resulting tree's right subchild remains in degenerate list form.
  Thus, at each iteration of the second loop starting at line 4,
  we have $t$'s right child in degenerate list form.

  Furthermore, upon each iteration of the loop starting at line 4,
  we move one more node into the right subtree of $t$.
  Thus, this loop eventually halts, and $t$ is left with a null left child.
  As $t$'s right subtree is also in degenerate list form,
  $t$ is left in degenerate list form.

  Clearly, if $t_1$ and $t_2$ are both in degenerate list form,
  then $\mathrm{list}(t_1) = \mathrm{list}(t_2)$ if and only if $t_1 = t_2$.
  Thus, if $\mathrm{list}(t_1) = \mathrm{list}(t_2)$, then $t_1$ and $t_2$
  can both be transformed into the same degenerate list structure
  useing the $\rho$ and $\theta$.
  Thus, $t_1$ can be transformed into $t_2$.

\end{proof}

\section{Invariance with respect to a function}

All previous work on these topics share one downside: they require programmers
to express their invariants in formal logic. This could potentially be
difficult. One class of invariants that can be expressed through codes is
\emph{invariance with respect to a function}.

\begin{definition} We say that a program $P$ is invariant with respect to a
  function $f$ if whenever $f(x)=f(y)$, we have $P(x)=P(y)$.
\end{definition}

For example, if a programmer defines a tree or heap data type with a function
$\mathrm{list}$ mapping the data type to lists,
then nearly every function written on this data type should be invariant with
respect to the $\mathrm{list}$ function,
as these data types are meant to represent the lists perfectly (while allowing
for faster algorithms).

We regard this problem as very difficult, because the function $f$ can be
expressed with arbitrary code and thus encode more complicated properties than
first order logic. One approach comes from the following observation:

\begin{lemma} Let $P : T \to T'$ and $f : T' \to Z$.
  Then $P$ is invariant with respect to $f$ if and only if
  there exists a program $\widetilde{P} : T'\to Z$
  such that $P = \widetilde{P} \circ f$
\end{lemma}

  \[
    \begin{tikzcd}
      BSTs \arrow{rr}{P} \arrow{rd}{list} &   & Z \\
      & Lists \arrow[dashed]{ru}{\widetilde{P}} &   \\
    \end{tikzcd}
  \]



%
% ---- Bibliography ----
%
\bibliographystyle{splncs}
\bibliography{robustness}

\end{document}

%\titlerunning{Verifying Alegebraic Proper}
% abbreviated title (for running head)
% also used for the TOC unless \toctitle is used
%\authorrunning{Ivar Ekeland et al.} % abbreviated author list (for running head)
%%%% list of authors for the TOC (use if author list has to be modified)
%\tocauthor{Ivar Ekeland, Roger Temam, Jeffrey Dean, David Grove,
%Craig Chambers, Kim B. Bruce, and Elisa Bertino}
%\email{I.Ekeland@princeton.edu},\\ WWW home page:
%\texttt{http://users/\homedir iekeland/web/welcome.html}
%\and
%Universit\'{e} de Paris-Sud,
%Laboratoire d'Analyse Num\'{e}rique, B\^{a}timent 425,\\
%F-91405 Orsay Cedex, France}
